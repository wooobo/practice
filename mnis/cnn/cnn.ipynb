{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CNN\n",
    "\n",
    "## 구조\n",
    "- 입력 레이어\n",
    "- 합성곱 계층 + 활성화 함수\n",
    "- 풀링 레이어\n",
    "- 완전 연결 계층"
   ],
   "id": "65d867216e57e91b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/75211cnn-schema1.webp)  \n",
    "[출처](https://www.analyticsvidhya.com/blog/2021/08/beginners-guide-to-convolutional-neural-network-with-implementation-in-python/)"
   ],
   "id": "2e04acf87a7a2703"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T13:21:54.612271Z",
     "start_time": "2025-02-12T13:21:52.891299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import os\n",
    "import os\n",
    "import gzip\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n"
   ],
   "id": "7d403ed16f0a6e6a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T13:41:29.194772Z",
     "start_time": "2025-02-12T13:41:29.184747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "# # MNIST를 다운받을 경로\n",
    "url = 'https://ossci-datasets.s3.amazonaws.com/mnist/'\n",
    "# # MNIST를 저장할 디렉토리 (colab 사용 시, 기본 디렉토리는 `/content`)\n",
    "dataset_dir = os.path.join(os.getcwd(), 'data')\n",
    "# \n",
    "# # MNIST 데이터셋의 파일명 (딕셔너리)\n",
    "key_file = {\n",
    "    'train_img':'train-images-idx3-ubyte.gz',\n",
    "    'train_label':'train-labels-idx1-ubyte.gz',\n",
    "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
    "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
    "}\n",
    "\n",
    "# # 해당 경로가 없을 시 디렉토리 새로 생성\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "# 해당 경로에 존재하지 않는 파일을 모두 다운로드\n",
    "for filename in key_file.values():\n",
    "    if filename not in os.listdir(dataset_dir):\n",
    "        urlretrieve(url + filename, os.path.join(dataset_dir, filename))\n",
    "        print(\"Downloaded %s to %s\" % (filename, dataset_dir))"
   ],
   "id": "310f2fb12c0b6f83",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-12T13:21:54.625462Z",
     "start_time": "2025-02-12T13:21:54.620919Z"
    }
   },
   "source": [
    "class MNIST:\n",
    "    def __init__(self):\n",
    "        self.model = self\n",
    "        self.file_paths = {\n",
    "            'train_img': 'train-images-idx3-ubyte.gz',\n",
    "            'train_label': 'train-labels-idx1-ubyte.gz',\n",
    "            'test_img': 't10k-images-idx3-ubyte.gz',\n",
    "            'test_label': 't10k-labels-idx1-ubyte.gz'\n",
    "        }\n",
    "        self.data_dir = 'data'  # 데이터 폴더 경로\n",
    "        self.dataset = self.load_dataset()\n",
    "\n",
    "    def load_dataset(self):\n",
    "        \"\"\"데이터셋을 로드하는 함수\"\"\"\n",
    "        dataset = {}\n",
    "        for key, value in self.file_paths.items():\n",
    "            if 'img' in key:\n",
    "                dataset[key] = self.load_images(value)\n",
    "            else:\n",
    "                dataset[key] = self.load_labels(value)\n",
    "        return dataset\n",
    "    \n",
    "    def load_labels(self, filename):\n",
    "        \"\"\"레이블 파일을 로드하는 함수\"\"\"\n",
    "        path = os.path.join(self.data_dir, filename)\n",
    "        with gzip.open(path, 'rb') as f:\n",
    "            labels = np.frombuffer(f.read(), dtype=np.uint8, offset=8)\n",
    "        return labels\n",
    "    \n",
    "    \n",
    "    def load_images(self, filename):\n",
    "        \"\"\"이미지 파일을 로드하는 함수\"\"\"\n",
    "        path = os.path.join(self.data_dir, filename)\n",
    "        with gzip.open(path, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), dtype=np.uint8, offset=16)\n",
    "            images = data.reshape(-1, 28, 28)  # (N, 28, 28) 형식으로 변환\n",
    "        return images\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T13:32:30.174799Z",
     "start_time": "2025-02-12T13:32:30.157481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 데이터 로더 클래스\n",
    "class MNISTDataset(data.Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx].astype(np.float32) / 255.0  # 정규화\n",
    "        img = np.expand_dims(img, axis=0)  # (28, 28) -> (1, 28, 28)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return torch.tensor(img, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# CNN 모델 정의\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 학습 함수\n",
    "def training(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "# 평가 함수\n",
    "def evaluation(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# 전체 학습 루프\n",
    "def training_loop(model, train_loader, test_loader, criterion, optimizer, device, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = training(model, train_loader, criterion, optimizer, device)\n",
    "        test_accuracy = evaluation(model, test_loader, device)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Loss = {train_loss:.4f}, Test Accuracy = {test_accuracy:.2f}%\")\n"
   ],
   "id": "5aa8cb7b4166ca52",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T13:32:51.183763Z",
     "start_time": "2025-02-12T13:32:51.032414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 데이터 로드\n",
    "mnist = MNIST()\n",
    "train_dataset = MNISTDataset(mnist.dataset['train_img'], mnist.dataset['train_label'])\n",
    "test_dataset = MNISTDataset(mnist.dataset['test_img'], mnist.dataset['test_label'])\n",
    "\n",
    "print(mnist.dataset['train_img'].shape, mnist.dataset['train_label'].shape, mnist.dataset['test_img'].shape, mnist.dataset['test_label'].shape)"
   ],
   "id": "777cbb5c1f9957f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T13:32:56.116589Z",
     "start_time": "2025-02-12T13:32:56.111190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ],
   "id": "69e007a10a9f237a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T13:37:51.501871Z",
     "start_time": "2025-02-12T13:36:06.140978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 모델, 손실 함수, 옵티마이저 정의\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 실행\n",
    "training_loop(model, train_loader, test_loader, criterion, optimizer, device, epochs=5)"
   ],
   "id": "b33d5a0bcb56e498",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.1777, Test Accuracy = 98.46%\n",
      "Epoch 2: Loss = 0.0533, Test Accuracy = 98.84%\n",
      "Epoch 3: Loss = 0.0355, Test Accuracy = 98.78%\n",
      "Epoch 4: Loss = 0.0274, Test Accuracy = 99.05%\n",
      "Epoch 5: Loss = 0.0203, Test Accuracy = 99.07%\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
