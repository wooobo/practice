{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.079731Z",
     "start_time": "2025-02-11T06:47:34.052275Z"
    }
   },
   "source": "import torch",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.089422Z",
     "start_time": "2025-02-11T06:47:35.083271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_a = torch.tensor([[10, 20], [30, 40]])\n",
    "tensor_b = torch.tensor([[50, 20], [40, 60]])"
   ],
   "id": "7fed4a2da07bc24",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## dim 이란?\n",
    "dim은 PyTorch 텐서에서 특정 축(axis)을 따라 연산을 수행할지를 결정하는 매개변수입니다.\n",
    "\n",
    "### dim=0 (행 기준 연산, 열 별 최댓값/최솟값)\n",
    "각 열(column)마다 최대/최소 값을 찾습니다.  \n",
    "즉, 세로 방향(axis=0)으로 연산하여 행(row)을 축소합니다.  \n",
    "반환값:  \n",
    ".values: 최댓값/최솟값 텐서  \n",
    ".indices: 해당 최댓값/최솟값이 위치한 인덱스  \n",
    "\n",
    "## tensor.argmax()\n",
    "- argmax: 텐서의 최대값이 있는 인덱스를 반환합니다.\n",
    "- argmin: 텐서의 최소값이 있는 인덱스를 반환합니다.\n"
   ],
   "id": "68562a36c85ba30b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.114753Z",
     "start_time": "2025-02-11T06:47:35.094437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(tensor_a)\n",
    "print(\"shape :\", tensor_a.shape)\n",
    "print(\"dimention 지정 안했을때 max : \", torch.max(tensor_a))\n",
    "print(\"dim = 0 일때 max : \", torch.max(tensor_a, dim=0).values)\n",
    "print(\"dim = 1 일때 max : \", torch.max(tensor_a, dim=1).values)\n",
    "\n",
    "print(\"dimention 지정 안했을때 min : \", torch.min(tensor_a))\n",
    "print(\"dim = 0 일때 min : \", torch.min(tensor_a, dim=0).values)\n",
    "print(\"dim = 1 일때 min : \", torch.min(tensor_a, dim=1).values)"
   ],
   "id": "94e29f5e4061ed24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10, 20],\n",
      "        [30, 40]])\n",
      "shape : torch.Size([2, 2])\n",
      "dimention 지정 안했을때 max :  tensor(40)\n",
      "dim = 0 일때 max :  tensor([30, 40])\n",
      "dim = 1 일때 max :  tensor([20, 40])\n",
      "dimention 지정 안했을때 min :  tensor(10)\n",
      "dim = 0 일때 min :  tensor([10, 20])\n",
      "dim = 1 일때 min :  tensor([10, 30])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.141874Z",
     "start_time": "2025-02-11T06:47:35.135707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(tensor_b)\n",
    "print(\"shape :\", tensor_b.shape)\n",
    "print(\"dimention 지정 안했을때 max : \", torch.max(tensor_b))\n",
    "print(\"dim = 0 일때 max :  \", torch.max(tensor_b, dim=0).values)\n",
    "print(\"dim = 1 일때 max : \", torch.max(tensor_b, dim=1).values)\n",
    "\n",
    "print(\"dimention 지정 안했을때 min : \", torch.min(tensor_b))\n",
    "print(\"dim = 0 일때 min : \", torch.min(tensor_b, dim=0).values)\n",
    "print(\"dim = 1 일때 min : \", torch.min(tensor_b, dim=1).values)"
   ],
   "id": "fa32e2b30bd4b28c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50, 20],\n",
      "        [40, 60]])\n",
      "shape : torch.Size([2, 2])\n",
      "dimention 지정 안했을때 max :  tensor(60)\n",
      "dim = 0 일때 max :   tensor([50, 60])\n",
      "dim = 1 일때 max :  tensor([50, 60])\n",
      "dimention 지정 안했을때 min :  tensor(20)\n",
      "dim = 0 일때 min :  tensor([40, 20])\n",
      "dim = 1 일때 min :  tensor([20, 40])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.160023Z",
     "start_time": "2025-02-11T06:47:35.152861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4차원 텐서 (batch=2, channels=2, height=3, width=3)\n",
    "tensor_c = torch.tensor(\n",
    "    [\n",
    "        [  # 첫 번째 배치 (batch=0)\n",
    "            [  # 첫 번째 채널 (channel=0)\n",
    "                [1, 2, 3, 4, 5],\n",
    "                [6, 7, 8, 9, 10],\n",
    "                [11, 12, 13, 14, 15],\n",
    "                [16, 17, 18, 19, 20]\n",
    "            ],\n",
    "            [  # 두 번째 채널 (channel=1)\n",
    "                [21, 22, 23, 24, 25],\n",
    "                [26, 27, 28, 29, 30],\n",
    "                [31, 32, 33, 34, 35],\n",
    "                [36, 37, 38, 39, 40]\n",
    "            ],\n",
    "            [  # 세 번째 채널 (channel=2)\n",
    "                [41, 42, 43, 44, 45],\n",
    "                [46, 47, 48, 49, 50],\n",
    "                [51, 52, 53, 54, 55],\n",
    "                [56, 57, 58, 59, 60]\n",
    "            ]\n",
    "        ],\n",
    "        [  # 두 번째 배치 (batch=1)\n",
    "            [  # 첫 번째 채널 (channel=0)\n",
    "                [61, 62, 63, 64, 65],\n",
    "                [66, 67, 68, 69, 70],\n",
    "                [71, 72, 73, 74, 75],\n",
    "                [76, 77, 78, 79, 80]\n",
    "            ],\n",
    "            [  # 두 번째 채널 (channel=1)\n",
    "                [81, 82, 83, 84, 85],\n",
    "                [86, 87, 88, 89, 90],\n",
    "                [91, 92, 93, 94, 95],\n",
    "                [96, 97, 98, 99, 100]\n",
    "            ],\n",
    "            [  # 세 번째 채널 (channel=2)\n",
    "                [101, 102, 103, 104, 105],\n",
    "                [106, 107, 108, 109, 110],\n",
    "                [111, 112, 113, 114, 115],\n",
    "                [116, 117, 118, 119, 120]\n",
    "            ]\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "max_values0 = torch.max(tensor_c, dim=0).values  # height(4) 방향으로 최대값 계산\n",
    "max_values1 = torch.max(tensor_c, dim=1).values  # height(4) 방향으로 최대값 계산\n",
    "max_values2 = torch.max(tensor_c, dim=2).values  # height(4) 방향으로 최대값 계산\n",
    "max_values3 = torch.max(tensor_c, dim=3).values  # height(4) 방향으로 최대값 계산\n",
    "print(\"max_values0 : \", max_values0.shape)  # torch.Size([3, 4, 5])\n",
    "print(max_values0)\n",
    "print(\"---------------------\")\n",
    "print(\"max_values1 : \", max_values1.shape)  # torch.Size([2, 4, 5])\n",
    "print(max_values1)\n",
    "print(\"---------------------\")\n",
    "print(\"max_values2 : \", max_values2.shape)  # torch.Size([2, 3, 5])\n",
    "print(max_values2)\n",
    "print(\"---------------------\")\n",
    "print(\"max_values3 : \", max_values3.shape)  # torch.Size([2, 3, 4])\n",
    "print(max_values3)\n"
   ],
   "id": "b0d09025b1f66608",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_values0 :  torch.Size([3, 4, 5])\n",
      "tensor([[[ 61,  62,  63,  64,  65],\n",
      "         [ 66,  67,  68,  69,  70],\n",
      "         [ 71,  72,  73,  74,  75],\n",
      "         [ 76,  77,  78,  79,  80]],\n",
      "\n",
      "        [[ 81,  82,  83,  84,  85],\n",
      "         [ 86,  87,  88,  89,  90],\n",
      "         [ 91,  92,  93,  94,  95],\n",
      "         [ 96,  97,  98,  99, 100]],\n",
      "\n",
      "        [[101, 102, 103, 104, 105],\n",
      "         [106, 107, 108, 109, 110],\n",
      "         [111, 112, 113, 114, 115],\n",
      "         [116, 117, 118, 119, 120]]])\n",
      "---------------------\n",
      "max_values1 :  torch.Size([2, 4, 5])\n",
      "tensor([[[ 41,  42,  43,  44,  45],\n",
      "         [ 46,  47,  48,  49,  50],\n",
      "         [ 51,  52,  53,  54,  55],\n",
      "         [ 56,  57,  58,  59,  60]],\n",
      "\n",
      "        [[101, 102, 103, 104, 105],\n",
      "         [106, 107, 108, 109, 110],\n",
      "         [111, 112, 113, 114, 115],\n",
      "         [116, 117, 118, 119, 120]]])\n",
      "---------------------\n",
      "max_values2 :  torch.Size([2, 3, 5])\n",
      "tensor([[[ 16,  17,  18,  19,  20],\n",
      "         [ 36,  37,  38,  39,  40],\n",
      "         [ 56,  57,  58,  59,  60]],\n",
      "\n",
      "        [[ 76,  77,  78,  79,  80],\n",
      "         [ 96,  97,  98,  99, 100],\n",
      "         [116, 117, 118, 119, 120]]])\n",
      "---------------------\n",
      "max_values3 :  torch.Size([2, 3, 4])\n",
      "tensor([[[  5,  10,  15,  20],\n",
      "         [ 25,  30,  35,  40],\n",
      "         [ 45,  50,  55,  60]],\n",
      "\n",
      "        [[ 65,  70,  75,  80],\n",
      "         [ 85,  90,  95, 100],\n",
      "         [105, 110, 115, 120]]])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### dim 쉽게 기억하는 방법\n",
    "- dim=N에서 N번째 축을 없애는 방향으로 연산  "
   ],
   "id": "5a8649c1d3815c54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.177294Z",
     "start_time": "2025-02-11T06:47:35.172857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3x3 Tensor 생성\n",
    "tensor = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]])\n",
    "\n",
    "# 전체 합계\n",
    "print(torch.sum(tensor))  # 45\n",
    "\n",
    "# 열을 기준으로 합계 (dim=0) → 세로 방향 합\n",
    "print(torch.sum(tensor, dim=0))  # tensor([12, 15, 18])\n",
    "\n",
    "# 행을 기준으로 합계 (dim=1) → 가로 방향 합\n",
    "print(torch.sum(tensor, dim=1))  # tensor([ 6, 15, 24])\n",
    "\n",
    "# 최대값 구하기\n",
    "print(torch.max(tensor, dim=1))  # (tensor([3, 6, 9]), tensor([2, 2, 2]))  (값, 인덱스)"
   ],
   "id": "5cbdbf02c9f7edb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45)\n",
      "tensor([12, 15, 18])\n",
      "tensor([ 6, 15, 24])\n",
      "torch.return_types.max(\n",
      "values=tensor([3, 6, 9]),\n",
      "indices=tensor([2, 2, 2]))\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 행렬 및 벡터 계산\n",
    "- dot: 내적\n",
    "    - torch.dot(a,b)\n",
    "    - a.dot(b) "
   ],
   "id": "2e6c44faf51e4b63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.189967Z",
     "start_time": "2025-02-11T06:47:35.186248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "v1 = torch.tensor([1, 2])\n",
    "u1 = torch.tensor([3, 4])\n",
    "\n",
    "print(torch.dot(v1, u1))  # 1*3 + 2*4 = 11\n",
    "print(v1.dot(u1))  # 1*3 + 2*4 = 11"
   ],
   "id": "4ef218156084e8d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11)\n",
      "tensor(11)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### matmul: 행렬곱\n",
    "- torch.matmul(a,b)\n",
    "- a.matmul(b)"
   ],
   "id": "c266c8cf14de2875"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.220442Z",
     "start_time": "2025-02-11T06:47:35.213951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A = torch.tensor([[1, 2], [3, 4]])\n",
    "B = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "print(torch.matmul(A, B))\n",
    "print(A.matmul(B))"
   ],
   "id": "b4a93eec59f2c524",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Broadcasting\n",
    "\n",
    "- 브로드캐스팅은 텐서의 모양을 동적으로 확장하여 연산을 수행하는 기능입니다.\n",
    "- scalar: 값으로 텐서 원소 변경하기\n",
    "    - indexing으로 텐서 원소에 접근후 scalar 값으로 원소 변경  "
   ],
   "id": "c17d3cf201a05ffb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.243292Z",
     "start_time": "2025-02-11T06:47:35.229162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_a = torch.rand(3, 2)\n",
    "print(tensor_a)\n",
    "\n",
    "tensor_a[0, :] = 10\n",
    "print(tensor_a)"
   ],
   "id": "5e9e6015acff0d06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1654, 0.1054],\n",
      "        [0.6577, 0.8478],\n",
      "        [0.6862, 0.1412]])\n",
      "tensor([[10.0000, 10.0000],\n",
      "        [ 0.6577,  0.8478],\n",
      "        [ 0.6862,  0.1412]])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "텐서 값으로 텐서 원소 변경",
   "id": "2ed5bead8f1a180f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.253971Z",
     "start_time": "2025-02-11T06:47:35.250230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_a = torch.rand(3, 2)\n",
    "print(tensor_a)\n",
    "\n",
    "tensor_a[:, :] = torch.tensor([0, 1])\n",
    "print(tensor_a)"
   ],
   "id": "dd2c6f6a8b376773",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9226, 0.7750],\n",
      "        [0.7868, 0.6160],\n",
      "        [0.5964, 0.6026]])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "차원이 다른 텐서 간의 계산을 Broadcasting을 통해 수행",
   "id": "b48b6884bbd75da0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.266430Z",
     "start_time": "2025-02-11T06:47:35.262385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_a = torch.eye(3)\n",
    "print(tensor_a)\n",
    "\n",
    "tensor_b = torch.tensor([1, 2, 3])\n",
    "print(tensor_b)\n",
    "\n",
    "print(\"A+B : \", tensor_a + tensor_b)"
   ],
   "id": "6ffc25223c6316ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([1, 2, 3])\n",
      "A+B :  tensor([[2., 2., 3.],\n",
      "        [1., 3., 3.],\n",
      "        [1., 2., 4.]])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.280748Z",
     "start_time": "2025-02-11T06:47:35.277990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_a = torch.eye(3)\n",
    "print(tensor_a)\n",
    "tensor_b = torch.tensor([1, 2, 3]).reshape(3, 1)\n",
    "print(tensor_b)\n",
    "\n",
    "print(\"A+B : \", tensor_a + tensor_b)"
   ],
   "id": "297ab73a3a099200",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "A+B :  tensor([[2., 1., 1.],\n",
      "        [2., 3., 2.],\n",
      "        [3., 3., 4.]])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### unsqueeze 사용",
   "id": "e522fdf53c4d96b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.311107Z",
     "start_time": "2025-02-11T06:47:35.307069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1D 텐서 생성\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(\"Original Tensor:\", tensor.shape)  # (3,)\n",
    "print(\"Original Tensor:\", tensor)  # (3,)\n",
    "\n",
    "# 차원 추가: 첫 번째 차원(0번)에 추가\n",
    "tensor_unsqueezed = torch.unsqueeze(tensor, dim=0)\n",
    "print(\"Unsqueezed Tensor (dim=0):\", tensor_unsqueezed.shape)  # (1, 3)\n",
    "print(\"Unsqueezed Tensor (dim=0):\", tensor_unsqueezed)  # (1, 3)\n",
    "\n",
    "# 차원 추가: 두 번째 차원(1번)에 추가\n",
    "tensor_unsqueezed_1 = torch.unsqueeze(tensor, dim=1)\n",
    "print(\"Unsqueezed Tensor (dim=1):\", tensor_unsqueezed_1.shape)  # (3, 1)\n",
    "print(\"Unsqueezed Tensor (dim=1):\", tensor_unsqueezed_1)  # (3, 1)\n"
   ],
   "id": "628edaf490f99abc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: torch.Size([3])\n",
      "Original Tensor: tensor([1, 2, 3])\n",
      "Unsqueezed Tensor (dim=0): torch.Size([1, 3])\n",
      "Unsqueezed Tensor (dim=0): tensor([[1, 2, 3]])\n",
      "Unsqueezed Tensor (dim=1): torch.Size([3, 1])\n",
      "Unsqueezed Tensor (dim=1): tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### COO Sparse Tensor \n",
    "\n",
    "#### COO 형식의 개념\n",
    "- 좌표(indices): 값이 있는 요소의 위치를 나타냅니다.  \n",
    "- 값(values): 실제 값들을 저장합니다.  \n",
    "- 크기(size): 전체 텐서의 크기 (생략 가능)."
   ],
   "id": "60f26a5ea4da54aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.329154Z",
     "start_time": "2025-02-11T06:47:35.322140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 좌표 (indices)\n",
    "indices = torch.tensor([[0, 1, 1],  # row indices\n",
    "                        [2, 0, 2]])  # col indices\n",
    "\n",
    "# 값 (values)\n",
    "values = torch.tensor([3, 4, 5])  # 해당 위치의 값\n",
    "\n",
    "# 크기 지정 (3x3 행렬)\n",
    "size = (3, 3)\n",
    "\n",
    "# 희소 텐서 생성\n",
    "sparse_tensor = torch.sparse_coo_tensor(indices, values, size)\n",
    "\n",
    "# 출력\n",
    "print(\"희소 텐서:\")\n",
    "print(sparse_tensor)\n",
    "\n",
    "# 밀집(dense) 텐서로 변환\n",
    "dense_tensor = sparse_tensor.to_dense()\n",
    "print(\"\\nDense 텐서:\")\n",
    "print(dense_tensor)"
   ],
   "id": "d8c2259c5da2e72d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "희소 텐서:\n",
      "tensor(indices=tensor([[0, 1, 1],\n",
      "                       [2, 0, 2]]),\n",
      "       values=tensor([3, 4, 5]),\n",
      "       size=(3, 3), nnz=3, layout=torch.sparse_coo)\n",
      "\n",
      "Dense 텐서:\n",
      "tensor([[0, 0, 3],\n",
      "        [4, 0, 5],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "COO 단점\n",
    "- 중복 저장\n",
    "- 특정 원소에 반복접근시 비효율적으로 접근"
   ],
   "id": "fc52f5e82d227c1a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### CSR/CSC Sparse Tensor\n",
    "- CSR: Compressed Sparse Row\n",
    "- CSC: Compressed Sparse Column"
   ],
   "id": "60a87afbf47cc196"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.350854Z",
     "start_time": "2025-02-11T06:47:35.339088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t = torch.tensor([[0, 0, 3, 0, 4],\n",
    "                  [0, 0, 5, 6, 0],\n",
    "                  [7, 8, 0, 0, 0]])\n",
    "\n",
    "print(t)\n",
    "# CSR 형식으로 변환\n",
    "print(t.to_sparse_csr())\n",
    "\n",
    "# CSC 형식으로 변환\n",
    "print(t.to_sparse_csc())"
   ],
   "id": "4e1622cad9f91041",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 3, 0, 4],\n",
      "        [0, 0, 5, 6, 0],\n",
      "        [7, 8, 0, 0, 0]])\n",
      "tensor(crow_indices=tensor([0, 2, 4, 6]),\n",
      "       col_indices=tensor([2, 4, 2, 3, 0, 1]),\n",
      "       values=tensor([3, 4, 5, 6, 7, 8]), size=(3, 5), nnz=6,\n",
      "       layout=torch.sparse_csr)\n",
      "tensor(ccol_indices=tensor([0, 1, 2, 4, 5, 6]),\n",
      "       row_indices=tensor([2, 2, 0, 1, 1, 0]),\n",
      "       values=tensor([7, 8, 3, 5, 6, 4]), size=(3, 5), nnz=6,\n",
      "       layout=torch.sparse_csc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zw/_n2013wn763fp6tt7wpy6xdw0000gn/T/ipykernel_46829/3614091314.py:7: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:55.)\n",
      "  print(t.to_sparse_csr())\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sparse CSC Tensor",
   "id": "f663ce64f13abf62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.369162Z",
     "start_time": "2025-02-11T06:47:35.363322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ccol_indices = torch.tensor([0, 2, 2])  # 0이 아닌 열의 위치(첫번째는 무조건 0), 즉 column_pointer\n",
    "row_indices = torch.tensor([0, 1])  # 0이 아닌 값의 행 위치\n",
    "values = torch.tensor([1, 2])  # 0이 아닌 값\n",
    "\n",
    "csc = torch.sparse_csc_tensor(ccol_indices=ccol_indices, row_indices=row_indices, values=values, size=(3, 2))\n",
    "\n",
    "print(csc)\n",
    "print(csc.to_dense())"
   ],
   "id": "c1ded4c9dbd8f210",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(ccol_indices=tensor([0, 2, 2]),\n",
      "       row_indices=tensor([0, 1]),\n",
      "       values=tensor([1, 2]), size=(3, 2), nnz=2, layout=torch.sparse_csc)\n",
      "tensor([[1, 0],\n",
      "        [2, 0],\n",
      "        [0, 0]])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Sparse Tensor 필요성\n",
    "- 메모리 절약\n",
    "- 연산 속도 향상\n",
    "- 아주 큰 크기의 matrix 를 구성할때 일반적인 dense tensor 는 메모리 아웃 현상이 발생하지만, sparse tensor 는 메모리 아웃현상이 발생하지 않습니다.\n",
    "    - to_dense(): sparse tensor 를 dense tensor 로 변환  "
   ],
   "id": "6cacfee28561002f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.383553Z",
     "start_time": "2025-02-11T06:47:35.378438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "i = torch.randint(0, 100000, (200000,)).reshape(2, -1)\n",
    "v = torch.rand(100000)\n",
    "coo_sparse_tensor = torch.sparse_coo_tensor(indices=i, values=v, size=(100000, 100000))"
   ],
   "id": "3b7b6ff5207c00fa",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.410679Z",
     "start_time": "2025-02-11T06:47:35.407253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "crow = torch.randint(0, 100000, (100000,))\n",
    "col = torch.randint(0, 100000, (100000,))\n",
    "v = torch.rand(100000)\n",
    "csr_sparse_tensor = torch.sparse_csr_tensor(crow_indices=crow, col_indices=col, values=v)"
   ],
   "id": "8bbf66cb7eb1357c",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:35.415075Z",
     "start_time": "2025-02-11T06:47:35.413159Z"
    }
   },
   "cell_type": "code",
   "source": "# coo_sparse_tensor.to_dense() # error",
   "id": "d044b2a3ac8cd692",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# sparse tensor 곱 , 덧셈, 행렬곱",
   "id": "be95f900142f5ef6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:49:21.900096Z",
     "start_time": "2025-02-11T06:49:21.891190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 좌표 (indices)\n",
    "indices = torch.tensor([[0, 1, 1], [2, 0, 2]])  # 위치\n",
    "\n",
    "# 값 (values)\n",
    "values1 = torch.tensor([3, 4, 5])\n",
    "values2 = torch.tensor([1, 2, 3])\n",
    "\n",
    "# 크기\n",
    "size = (3, 3)\n",
    "\n",
    "# 두 개의 sparse 텐서 생성\n",
    "sparse_tensor1 = torch.sparse_coo_tensor(indices, values1, size)\n",
    "sparse_tensor2 = torch.sparse_coo_tensor(indices, values2, size)\n",
    "\n",
    "# sparse 텐서 덧셈\n",
    "sparse_add = sparse_tensor1 + sparse_tensor2\n",
    "\n",
    "# 출력\n",
    "print(\"희소 텐서 덧셈 결과:\")\n",
    "print(sparse_add)\n",
    "print(\"\\nDense 변환:\")\n",
    "print(sparse_add.to_dense())  # 밀집 텐서 변환"
   ],
   "id": "bf0e0af535b39bc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[0, 1, 1],\n",
      "                       [2, 0, 2]]),\n",
      "       values=tensor([3, 4, 5]),\n",
      "       size=(3, 3), nnz=3, layout=torch.sparse_coo)\n",
      "희소 텐서 덧셈 결과:\n",
      "tensor(indices=tensor([[0, 1, 1],\n",
      "                       [2, 0, 2]]),\n",
      "       values=tensor([4, 6, 8]),\n",
      "       size=(3, 3), nnz=3, layout=torch.sparse_coo)\n",
      "\n",
      "Dense 변환:\n",
      "tensor([[0, 0, 4],\n",
      "        [6, 0, 8],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:47:55.043596Z",
     "start_time": "2025-02-11T06:47:55.039319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sparse 텐서 간 원소 곱 (Element-wise Multiplication)\n",
    "sparse_mul = sparse_tensor1.mul(sparse_tensor2)\n",
    "\n",
    "# 출력\n",
    "print(\"\\n희소 텐서 원소 곱 결과:\")\n",
    "print(sparse_mul)\n",
    "print(\"\\nDense 변환:\")\n",
    "print(sparse_mul.to_dense())  # 밀집 변환\n",
    "\n"
   ],
   "id": "c59e3a351d2de967",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "희소 텐서 원소 곱 결과:\n",
      "tensor(indices=tensor([[0, 1, 1],\n",
      "                       [2, 0, 2]]),\n",
      "       values=tensor([ 3,  8, 15]),\n",
      "       size=(3, 3), nnz=3, layout=torch.sparse_coo)\n",
      "\n",
      "Dense 변환:\n",
      "tensor([[ 0,  0,  3],\n",
      "        [ 8,  0, 15],\n",
      "        [ 0,  0,  0]])\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T06:48:04.030895Z",
     "start_time": "2025-02-11T06:48:04.026904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 밀집 행렬(Dense Tensor)\n",
    "dense_matrix = torch.tensor([[1, 2, 3],\n",
    "                             [4, 5, 6],\n",
    "                             [7, 8, 9]])\n",
    "\n",
    "# sparse 텐서와 dense 텐서 간 행렬곱\n",
    "sparse_mm = torch.sparse.mm(sparse_tensor1, dense_matrix)\n",
    "\n",
    "# 출력\n",
    "print(\"\\n희소 텐서 행렬곱 결과:\")\n",
    "print(sparse_mm)\n",
    "\n",
    "# 3차원 sparse tensor 행렬곱 불가능!\n",
    "# 2차원까지만 행렬곱 가증\n"
   ],
   "id": "2f07911aeb00af9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "희소 텐서 행렬곱 결과:\n",
      "tensor([[21, 24, 27],\n",
      "        [39, 48, 57],\n",
      "        [ 0,  0,  0]])\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Sparse Tensor 요소 분석\n",
    "```python\n",
    "tensor(indices=tensor([[0, 1, 1],\n",
    "                       [2, 0, 2]]),\n",
    "       values=tensor([4, 6, 8]),\n",
    "       size=(3, 3), nnz=3, layout=torch.sparse_coo)\n",
    "```\n",
    "\n",
    "1. indices (좌표 인덱스) \n",
    "```python\n",
    "tensor([[0, 1, 1],\n",
    "        [2, 0, 2]])\n",
    "```\n",
    "\n",
    "2. values (값)\n",
    "```python\n",
    "tensor([4, 6, 8])\n",
    "```\n",
    "\n",
    "3. size (텐서 크기)\n",
    "```python\n",
    "(3, 3)\n",
    "```\n",
    "\n",
    "4. nnz (0이 아닌 값의 개수). \n",
    "3\n"
   ],
   "id": "8e4e9d4d39565f8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### sparse tensor 의 indexing\n",
    "\n",
    "- 일반 텐서와 동일하게 indexing 이 가능\n",
    "    - slicing(\":\"을 사용)은 불가능 \n"
   ],
   "id": "93f1fe9d665f29b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T07:00:22.617081Z",
     "start_time": "2025-02-11T07:00:22.600017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.tensor([[0,1 ], [0, 2]], dtype=torch.float)\n",
    "b = torch.tensor([[[1,0], [0,0]], [[1,0], [0,0]]], dtype=torch.float)\n",
    "\n",
    "sparse_a = a.to_sparse()\n",
    "sparse_b = b.to_sparse()\n",
    "\n",
    "print(\"2차원 sparse tensor indexing\")\n",
    "print(a[0] == sparse_a[0].to_dense())\n",
    "\n",
    "print(\"3차원 sparse tensor indexing\")\n",
    "print(b[0] == sparse_b[0].to_dense())"
   ],
   "id": "35108d57a3dca551",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2차원 sparse tensor indexing\n",
      "tensor([True, True])\n",
      "3차원 sparse tensor indexing\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ba98c68711955cd0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
